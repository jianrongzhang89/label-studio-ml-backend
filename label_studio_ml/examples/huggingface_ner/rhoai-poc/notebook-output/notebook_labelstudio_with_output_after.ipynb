{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdc8cab4",
   "metadata": {},
   "source": [
    "# Workbench and Label Studio Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f8209d",
   "metadata": {},
   "source": [
    "First, install the dependencies, including label-studio-sdk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05241b64-faf9-439d-9ad0-536bc36138c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/app-root/lib64/python3.11/site-packages (25.1.1)\n",
      "Requirement already satisfied: transformers in /opt/app-root/lib64/python3.11/site-packages (4.52.3)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/app-root/lib64/python3.11/site-packages (from transformers) (0.32.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib64/python3.11/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib64/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib64/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/app-root/lib64/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/app-root/lib64/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/app-root/lib64/python3.11/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: accelerate in /opt/app-root/lib64/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/app-root/lib64/python3.11/site-packages (from accelerate) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib64/python3.11/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib64/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/app-root/lib64/python3.11/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/app-root/lib64/python3.11/site-packages (from accelerate) (2.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/app-root/lib64/python3.11/site-packages (from accelerate) (0.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/app-root/lib64/python3.11/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/app-root/lib64/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/app-root/lib64/python3.11/site-packages (from triton==3.3.0->torch>=2.0.0->accelerate) (74.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib64/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: datasets in /opt/app-root/lib64/python3.11/site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib64/python3.11/site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/app-root/lib64/python3.11/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/app-root/lib64/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib64/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/app-root/lib64/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/app-root/lib64/python3.11/site-packages (from datasets) (4.67.0)\n",
      "Requirement already satisfied: xxhash in /opt/app-root/lib64/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/app-root/lib64/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/app-root/lib64/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/app-root/lib64/python3.11/site-packages (from datasets) (0.32.2)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib64/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/app-root/lib64/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.0b3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.17.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.32.2->datasets) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: torch in /opt/app-root/lib64/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in /opt/app-root/lib64/python3.11/site-packages (0.22.0)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/app-root/lib64/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/app-root/lib64/python3.11/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib64/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib64/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/app-root/lib64/python3.11/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/app-root/lib64/python3.11/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/app-root/lib64/python3.11/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/app-root/lib64/python3.11/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/app-root/lib64/python3.11/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/app-root/lib64/python3.11/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/app-root/lib64/python3.11/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/app-root/lib64/python3.11/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/app-root/lib64/python3.11/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/app-root/lib64/python3.11/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/app-root/lib64/python3.11/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/app-root/lib64/python3.11/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/app-root/lib64/python3.11/site-packages (from triton==3.3.0->torch) (74.1.3)\n",
      "Requirement already satisfied: numpy in /opt/app-root/lib64/python3.11/site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/app-root/lib64/python3.11/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib64/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: seqeval in /opt/app-root/lib64/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/app-root/lib64/python3.11/site-packages (from seqeval) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/app-root/lib64/python3.11/site-packages (from seqeval) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/app-root/lib64/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/app-root/lib64/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/app-root/lib64/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
      "Requirement already satisfied: evaluate in /opt/app-root/lib64/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/app-root/lib64/python3.11/site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib64/python3.11/site-packages (from evaluate) (2.1.3)\n",
      "Requirement already satisfied: dill in /opt/app-root/lib64/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib64/python3.11/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/app-root/lib64/python3.11/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/app-root/lib64/python3.11/site-packages (from evaluate) (4.67.0)\n",
      "Requirement already satisfied: xxhash in /opt/app-root/lib64/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/app-root/lib64/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/app-root/lib64/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/app-root/lib64/python3.11/site-packages (from evaluate) (0.32.2)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib64/python3.11/site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.0.0->evaluate) (18.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/app-root/lib64/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.0b3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.17.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.19.0->evaluate) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.11/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.11/site-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.11/site-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: label-studio-sdk in /opt/app-root/lib64/python3.11/site-packages (1.0.16)\n",
      "Requirement already satisfied: Pillow>=10.0.1 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (11.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (1.4.4)\n",
      "Requirement already satisfied: datamodel-code-generator==0.26.1 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (0.26.1)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (0.27.2)\n",
      "Requirement already satisfied: ijson>=3.2.3 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (3.4.0)\n",
      "Requirement already satisfied: jsf<0.12.0,>=0.11.2 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (0.11.2)\n",
      "Requirement already satisfied: jsonschema>=4.23.0 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (4.23.0)\n",
      "Requirement already satisfied: lxml>=4.2.5 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (5.4.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (3.9.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.26.4 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (2.1.3)\n",
      "Requirement already satisfied: opencv-python<5.0.0,>=4.9.0 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (4.11.0.86)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (2.2.3)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (2.11.5)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (2.33.2)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (2.10.1)\n",
      "Requirement already satisfied: requests>=2.22.0 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (2.32.3)\n",
      "Requirement already satisfied: requests-mock==1.12.1 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (1.12.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (4.12.2)\n",
      "Requirement already satisfied: ujson>=5.8.0 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (5.10.0)\n",
      "Requirement already satisfied: xmljson==0.2.1 in /opt/app-root/lib64/python3.11/site-packages (from label-studio-sdk) (0.2.1)\n",
      "Requirement already satisfied: argcomplete<4.0,>=1.10 in /opt/app-root/lib64/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (3.6.2)\n",
      "Requirement already satisfied: black>=19.10b0 in /opt/app-root/lib64/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (24.10.0)\n",
      "Requirement already satisfied: genson<2.0,>=1.2.1 in /opt/app-root/lib64/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (1.3.0)\n",
      "Requirement already satisfied: inflect<6.0,>=4.1.0 in /opt/app-root/lib64/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (5.6.2)\n",
      "Requirement already satisfied: isort<6.0,>=4.3.21 in /opt/app-root/lib64/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (5.13.2)\n",
      "Requirement already satisfied: jinja2<4.0,>=2.10.1 in /opt/app-root/lib64/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (3.1.4)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib64/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (24.1)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /opt/app-root/lib64/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (6.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from jinja2<4.0,>=2.10.1->datamodel-code-generator==0.26.1->label-studio-sdk) (3.0.2)\n",
      "Requirement already satisfied: faker>=15.3.4 in /opt/app-root/lib64/python3.11/site-packages (from jsf<0.12.0,>=0.11.2->label-studio-sdk) (37.3.0)\n",
      "Requirement already satisfied: rstr>=3.2.0 in /opt/app-root/lib64/python3.11/site-packages (from jsf<0.12.0,>=0.11.2->label-studio-sdk) (3.2.2)\n",
      "Requirement already satisfied: smart-open>=6.3.0 in /opt/app-root/lib64/python3.11/site-packages (from smart-open[http]>=6.3.0->jsf<0.12.0,>=0.11.2->label-studio-sdk) (7.0.5)\n",
      "Requirement already satisfied: click in /opt/app-root/lib64/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/app-root/lib64/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/app-root/lib64/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib64/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk) (4.67.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/app-root/lib64/python3.11/site-packages (from pydantic>=1.9.2->label-studio-sdk) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/app-root/lib64/python3.11/site-packages (from pydantic>=1.9.2->label-studio-sdk) (0.4.1)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /opt/app-root/lib64/python3.11/site-packages (from pydantic[email]!=2.4.0,<3.0,>=1.10.0; python_version >= \"3.11\" and python_version < \"4.0\"->datamodel-code-generator==0.26.1->label-studio-sdk) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.22.0->label-studio-sdk) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.22.0->label-studio-sdk) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.22.0->label-studio-sdk) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.22.0->label-studio-sdk) (2024.8.30)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/app-root/lib64/python3.11/site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk) (1.0.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/app-root/lib64/python3.11/site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/app-root/lib64/python3.11/site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk) (4.3.6)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /opt/app-root/lib64/python3.11/site-packages (from email-validator>=2.0.0->pydantic[email]!=2.4.0,<3.0,>=1.10.0; python_version >= \"3.11\" and python_version < \"4.0\"->datamodel-code-generator==0.26.1->label-studio-sdk) (2.7.0)\n",
      "Requirement already satisfied: tzdata in /opt/app-root/lib64/python3.11/site-packages (from faker>=15.3.4->jsf<0.12.0,>=0.11.2->label-studio-sdk) (2024.2)\n",
      "Requirement already satisfied: anyio in /opt/app-root/lib64/python3.11/site-packages (from httpx>=0.21.2->label-studio-sdk) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.11/site-packages (from httpx>=0.21.2->label-studio-sdk) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib64/python3.11/site-packages (from httpx>=0.21.2->label-studio-sdk) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/app-root/lib64/python3.11/site-packages (from httpcore==1.*->httpx>=0.21.2->label-studio-sdk) (0.14.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=4.23.0->label-studio-sdk) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=4.23.0->label-studio-sdk) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=4.23.0->label-studio-sdk) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=4.23.0->label-studio-sdk) (0.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.11/site-packages (from pandas>=0.24.0->label-studio-sdk) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.11/site-packages (from pandas>=0.24.0->label-studio-sdk) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->label-studio-sdk) (1.16.0)\n",
      "Requirement already satisfied: wrapt in /opt/app-root/lib64/python3.11/site-packages (from smart-open>=6.3.0->smart-open[http]>=6.3.0->jsf<0.12.0,>=0.11.2->label-studio-sdk) (1.17.0rc1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -U transformers\n",
    "!pip install -U accelerate\n",
    "!pip install -U datasets\n",
    "!pip install -U torch torchvision\n",
    "!pip install -q diffusers  peft \n",
    "!pip install -q ipywidgets jupyterlab dataclass_wizard\n",
    "!pip install seqeval\n",
    "!pip install evaluate\n",
    "!pip install label-studio-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacbfa99",
   "metadata": {},
   "source": [
    "# Download training data from AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4486c53c-3303-4694-be34-e73b3ad6b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the following 3 variables before proceeding.\n",
    "import_test_data_from_aws = True # Set to True to import data stored in S3 bucket to the Label Studio project\n",
    "existing_project_id = 0 # If 0, a new project will be created. Otherwise set to the existing Label Studio project ID\n",
    "project_title = 'Huggingface Project' # Title of the Label Studio project. Ignored if existing_project_id > 0.\n",
    "\n",
    "# If you rerun this notebook with data that has been labelled in Label Studio, set the following variables\n",
    "import_test_data_from_aws = False\n",
    "existing_project_id = 17\n",
    "\n",
    "%run ./transfer-aws.ipynb\n",
    "\n",
    "prefix = \"ner-source\"  # Directory where the input data file is stored in AWS S3 bucket\n",
    "input_file='trainingdata-1000-before.json'\n",
    "    \n",
    "#Uncomment below lines if you run this notebook with the previously labelled sample training data by Label Studio (stored in S3 bucket)\n",
    "#prefix = \"ner-labelled\"\n",
    "#input_file='trainingdata-1000-after.json'\n",
    "\n",
    "s3_env: S3Env = init()\n",
    "dir_model = BucketMeta(\n",
    "                bucket_name=s3_env.bucket_name,\n",
    "                client=s3_env.client,\n",
    "                file_name=input_file,\n",
    "                prefix=prefix,\n",
    "                exclude_dirs_set=['logs'])\n",
    "\n",
    "if import_test_data_from_aws:\n",
    "    download_file(dir_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55b2d1e-45f5-4e32-9a06-66ae289a0beb",
   "metadata": {},
   "source": [
    "# Connect to Label Studio and Create a Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60002d1e-323b-4765-aa5c-ebca95a19185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use existing Lable Studio project with ID 17 and title NER Test - Labelled\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "# Define the URL where Label Studio is accessible and the API key for your user account\n",
    "LABEL_STUDIO_URL = os.environ.get('LABEL_STUDIO_URL')\n",
    "# API key is available at the Account & Settings > Access Tokens page in Label Studio UI\n",
    "API_KEY = os.environ.get('API_KEY')\n",
    "\n",
    "# Import the SDK client module\n",
    "from label_studio_sdk import Client\n",
    "from label_studio_sdk.label_interface.create import choices\n",
    "\n",
    "# Connect to the Label Studio Client and check the connection\n",
    "ls = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
    "ls.check_connection()\n",
    "\n",
    "# Label Studio project configuration\n",
    "label_config = \"\"\"\n",
    "<View>\n",
    "  <Labels name=\"label\" toName=\"text\">\n",
    "    <Label value=\"PER\" background=\"red\"/>\n",
    "    <Label value=\"ORG\" background=\"darkorange\"/>\n",
    "    <Label value=\"LOC\" background=\"orange\"/>\n",
    "    <Label value=\"MISC\" background=\"green\"/>\n",
    "  </Labels>\n",
    "  <Text name=\"text\" value=\"$text\"/>\n",
    "</View>\n",
    "    \"\"\"\n",
    "\n",
    "if existing_project_id == 0:\n",
    "    # Create a Label Studio project\n",
    "    project = ls.start_project(\n",
    "      title=project_title,\n",
    "      label_config=label_config,\n",
    "    )\n",
    "    print(f\"Created Lable Studio project {project_title} with ID {project.get_params()['id']}.\")\n",
    "else:\n",
    "    project = ls.get_project(existing_project_id)\n",
    "    project_title = project.get_params()['title']\n",
    "    print(f\"Use existing Lable Studio project with ID {existing_project_id} and title {project_title}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b7816-4a1a-4c68-a29c-212973283f00",
   "metadata": {},
   "source": [
    "Import Training Data into Label Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e737bb63-a2dc-4a6f-ac61-cb9150bcc8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-PER': 1,\n",
       " 'I-PER': 2,\n",
       " 'B-ORG': 3,\n",
       " 'I-ORG': 4,\n",
       " 'B-LOC': 5,\n",
       " 'I-LOC': 6,\n",
       " 'B-MISC': 7,\n",
       " 'I-MISC': 8}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tag names\n",
    "names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "index2tag = {idx:tag for idx, tag in enumerate(names)}\n",
    "tag2index = {tag:idx for idx, tag in enumerate(names)}\n",
    "tag2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f20308-9de3-4622-96e3-f9854b2b764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if import_test_data_from_aws:\n",
    "    result=project.import_tasks(tasks=input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1806e9d9-e8c5-4c9b-9fcd-dcb776c9c88f",
   "metadata": {},
   "source": [
    "Wait for user to review and update labels in Label Studio UI and export the labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc6bf5a-82a4-491d-a771-eb49aec04c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001 task(s) exported from Label Studio project\n"
     ]
    }
   ],
   "source": [
    "# After user has done labelling in Label Studio, retrieve that data from Label Studio\n",
    "tasks = project.get_tasks()\n",
    "tasks_count = len(tasks)\n",
    "if tasks_count == 0:\n",
    "    print('No tasks exported from Label Studio project')\n",
    "else:\n",
    "    print(f'{tasks_count} task(s) exported from Label Studio project')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7ad0d0-fbd0-43e6-b701-c980d7855382",
   "metadata": {},
   "source": [
    "# Create a tokenizer and data collator for the base NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e041ce8b-ff04-4be8-aca0-4aabcb1d0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "model_checkpoint = 'dslim/bert-base-NER'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f04a7-3a81-4d78-a6dc-b9efdc5d4eef",
   "metadata": {},
   "source": [
    "# Transform labelled data to a tokenized dataset for NER model fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ae60a22-4628-4390-aa3f-3e02794190ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_studio_sdk.label_interface.objects import PredictionValue\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Dict\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "import pathlib\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from datasets import Dataset, ClassLabel, Value, Sequence, Features\n",
    "from functools import partial\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "def is_valid_url(path):\n",
    "    # Check if the text is a valid URL\n",
    "    try:\n",
    "        result = urlparse(path)\n",
    "        return all([result.scheme, result.netloc])\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_preload_needed(url):\n",
    "    if url.startswith('upload') or url.startswith('/upload'):\n",
    "        url = '/data' + ('' if url.startswith('/') else '/') + url\n",
    "\n",
    "    is_uploaded_file = url.startswith('/data/upload')\n",
    "    is_local_storage_file = url.startswith('/data/') and '?d=' in url\n",
    "    is_cloud_storage_file = url.startswith('s3:') or url.startswith('gs:') or url.startswith('azure-blob:')\n",
    "    path_exists = os.path.exists(url)\n",
    "\n",
    "    return (\n",
    "        is_uploaded_file\n",
    "        or is_local_storage_file\n",
    "        or is_cloud_storage_file\n",
    "        or is_valid_url(url)\n",
    "        or path_exists\n",
    "    )\n",
    "\n",
    "def preload_task_data(task: Dict, value=None, read_file=True):\n",
    "    \"\"\" Preload task_data values using get_local_path() if values are URI/URL/local path.\n",
    "\n",
    "    Args:\n",
    "        task: Task root.\n",
    "        value: task['data'] if it's None.\n",
    "        read_file: If True, read file content. Otherwise, return file path only.\n",
    "\n",
    "    Returns:\n",
    "        Any: Preloaded task data value.\n",
    "    \"\"\"\n",
    "    # recursively preload dict\n",
    "    if isinstance(value, dict):\n",
    "        for key, item in value.items():\n",
    "            value[key] = preload_task_data(task=task, value=item, read_file=read_file)\n",
    "        return value\n",
    "\n",
    "    # recursively preload list\n",
    "    elif isinstance(value, list):\n",
    "        return [\n",
    "            preload_task_data(task=task, value=item, read_file=read_file)\n",
    "            for item in value\n",
    "        ]\n",
    "\n",
    "    # preload task data if value is URI/URL/local path\n",
    "    elif isinstance(value, str) and is_preload_needed(value):\n",
    "        filepath = self.get_local_path(url=value, task_id=task.get('id'))\n",
    "        if not read_file:\n",
    "            return filepath\n",
    "        with open(filepath, 'r') as f:\n",
    "            return f.read()\n",
    "\n",
    "    # keep value as is\n",
    "    return value\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            current_word = word_id\n",
    "            label =  -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            label = labels[word_id]\n",
    "            if label%2==1:\n",
    "                label = label + 1\n",
    "            new_labels.append(label)\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples['tokens'], truncation=True,is_split_into_words=True)\n",
    "    all_labels = examples['ner_tags']\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    tokenized_inputs['labels'] = new_labels\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f6dbe0-87fa-4502-9bde-2b10d927d8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset[0]: {'id': 31906, 'tokens': ['Inzamam-ul-Haq', ',', 'Salim', 'Malik', ',', 'Asif', 'Mujtaba', ',', 'Wasim', 'Akram', ',', 'Moin'], 'ner_tags': [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n"
     ]
    }
   ],
   "source": [
    "from label_studio_sdk.label_interface import LabelInterface\n",
    "label_interface = LabelInterface(config=label_config)\n",
    "\n",
    "ds_raw = []\n",
    "no_label = 'O'\n",
    "from_name, to_name, value = label_interface.get_first_tag_occurence('Labels', 'Text')\n",
    "for task in tasks:\n",
    "    if task['annotations'] != None:\n",
    "        for annotation in task['annotations']:\n",
    "            if not annotation.get('result'):\n",
    "                continue\n",
    "            spans = [{'label': r['value']['labels'][0], 'start': r['value']['start'], 'end': r['value']['end']} for r in annotation['result']]\n",
    "            spans = sorted(spans, key=lambda x: x['start'])\n",
    "            text = preload_task_data(task, task['data'][value])\n",
    "            # insert tokenizer.pad_token to the unlabeled chunks of the text in-between the labeled spans, as well as to the beginning and end of the text\n",
    "            last_end = 0\n",
    "            all_spans = []\n",
    "            for span in spans:\n",
    "                if last_end < span['start']:\n",
    "                    all_spans.append({'label': no_label, 'start': last_end, 'end': span['start']})\n",
    "                all_spans.append(span)\n",
    "                last_end = span['end']\n",
    "            if last_end < len(text):\n",
    "                all_spans.append({'label': no_label, 'start': last_end, 'end': len(text)})\n",
    "            # now tokenize chunks separately and add them to the dataset\n",
    "            item = {'id': task['id'], 'tokens': [], 'ner_tags': []}\n",
    "            for span in all_spans:\n",
    "                #tokens = tokenizer.tokenize(text[span['start']:span['end']])\n",
    "                tokens = str(text[span['start']:span['end']]).split()\n",
    "                item['tokens'].extend(tokens)\n",
    "                if span['label'] == no_label:\n",
    "                    item['ner_tags'].extend([tag2index[no_label]] * len(tokens))\n",
    "                else:\n",
    "                    label = 'B-' + span['label']\n",
    "                    item['ner_tags'].append(tag2index[label])\n",
    "                    if len(tokens) > 1:\n",
    "                        label = 'I-' + span['label']\n",
    "                        item['ner_tags'].extend([tag2index[label] for _ in range(1, len(tokens))])\n",
    "            ds_raw.append(item)\n",
    "print(\"Dataset[0]:\", ds_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a97ea25-43f9-4db1-9dd0-3d4eb283d63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fb5b3f4a0844b89c822508287261c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/814 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert to huggingface dataset\n",
    "# Define the features of your dataset\n",
    "features = Features({\n",
    "    'id': Value('string'),\n",
    "    'tokens': Sequence(Value('string')),\n",
    "    'ner_tags': Sequence(ClassLabel(names=list(tag2index.keys())))})\n",
    "\n",
    "hf_dataset = Dataset.from_list(ds_raw, features=features)\n",
    "tokenized_dataset_from_labelstudio = hf_dataset.map(tokenize_and_align_labels, \n",
    "                                   batched=True,\n",
    "                                   remove_columns=['id', 'tokens', 'ner_tags'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09797bd2-0fd5-430a-ac69-627696916e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 814\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_from_labelstudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de9288e-823c-4a76-a2e7-13e3eeb25ec7",
   "metadata": {},
   "source": [
    "# Prepare tokenized dataset for for model training validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38120518-78a3-4abb-9d6d-c0e0e830fea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "data = load_dataset(\"conllpp\")  # use published dataset for validation\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53ad3836-b751-4550-a387-8a95cafae555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_names(batch):\n",
    "    tag_name = {'ner_tags_str': [tags.int2str(idx) for idx in batch['ner_tags']]}\n",
    "    return tag_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61ef27af-2d9c-4ea3-8b0c-ba5a1c2cc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = data['validation'].features['ner_tags'].feature\n",
    "new_feature = data['validation'].features['ner_tags']\n",
    "label_names = new_feature.feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9841d879-8587-4ed5-9a4a-d84b692410ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a46a8566-e2a3-463c-a89b-5850664fb543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'ner_tags_str'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'ner_tags_str'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'ner_tags_str'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e3ac328-72f3-4d9b-ace1-6520f0aab5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            current_word = word_id\n",
    "            label =  -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            label = labels[word_id]\n",
    "            if label%2==1:\n",
    "                label = label + 1\n",
    "            new_labels.append(label)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea040121-7bc8-4c3d-a852-087ca54d84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples['tokens'], truncation=True,is_split_into_words=True)\n",
    "    all_labels = examples['ner_tags']\n",
    "    \n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    tokenized_inputs['labels'] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b6c2124-1b00-4de0-a9ea-8a33345b9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = data.map(tokenize_and_align_labels, batched=True, remove_columns=data['validation'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01b373a8-6c41-469f-bcd3-7ac9fcd77a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540b508-8242-4592-b12f-03df16a5b175",
   "metadata": {},
   "source": [
    "# Metrics for model training measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d1da581-2165-4ff1-b92e-6d9c81a635fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the whole dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "metric = evaluate.load('seqeval')\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [[label_names[p] for p, l in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\"precision\": all_metrics['overall_precision'],\n",
    "            \"recall\": all_metrics['overall_recall'],\n",
    "            \"f1\": all_metrics['overall_f1'],\n",
    "            \"accuracy\": all_metrics['overall_accuracy']}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7863e2-e670-4e5e-83f9-703c1e998495",
   "metadata": {},
   "source": [
    "# Train/fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2421b30-f2c0-484f-b391-3f8b42ddcece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, \n",
    "                                                        id2label=index2tag,\n",
    "                                                        label2id=tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e66d7815-f682-4b61-8685-a74d612465ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5505/539349262.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='204' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [204/204 00:30, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.130112</td>\n",
       "      <td>0.741967</td>\n",
       "      <td>0.865909</td>\n",
       "      <td>0.799161</td>\n",
       "      <td>0.959719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.134360</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.961387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=204, training_loss=0.39559053907207414, metrics={'train_runtime': 31.186, 'train_samples_per_second': 52.203, 'train_steps_per_second': 6.541, 'total_flos': 33593048761320.0, 'train_loss': 0.39559053907207414, 'epoch': 2.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "args = TrainingArguments(\"distilbert-finetuned-ner-1\",\n",
    "                         eval_strategy=\"epoch\",\n",
    "                         save_strategy=\"epoch\",\n",
    "                         learning_rate=2e-5,\n",
    "                         num_train_epochs=2,\n",
    "                         weight_decay=0.01)\n",
    "\n",
    "from transformers import Trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  train_dataset = tokenized_dataset_from_labelstudio,  \n",
    "                  #train_dataset = tokenized_datasets['train'].select(range(1000)),\n",
    "                  eval_dataset = tokenized_datasets['validation'].select(range(500)),\n",
    "                  data_collator = data_collator,\n",
    "                  compute_metrics = compute_metrics,\n",
    "                  tokenizer = tokenizer)\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29cf77f-8075-4c3d-8a12-0780531520ad",
   "metadata": {},
   "source": [
    "# Checking model predictions after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f2b283f-804f-4ab9-9c04-ebef3075c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.98914057),\n",
       "  'word': 'Bill Belichick',\n",
       "  'start': 0,\n",
       "  'end': 14},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': np.float32(0.7595738),\n",
       "  'word': 'University of North Carolina',\n",
       "  'start': 56,\n",
       "  'end': 84},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': np.float32(0.9593907),\n",
       "  'word': 'Patriots',\n",
       "  'start': 93,\n",
       "  'end': 101},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': np.float32(0.71790445),\n",
       "  'word': 'Chapel Hill',\n",
       "  'start': 155,\n",
       "  'end': 166}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "checkpoint = \"/opt/app-root/src/label-studio-ml-backend/label_studio_ml/examples/huggingface_ner/rhoai-poc/distilbert-finetuned-ner-1/checkpoint-204\"\n",
    "token_classifier = pipeline(\"token-classification\", model=checkpoint, aggregation_strategy=\"simple\")\n",
    "token_classifier(\"Bill Belichick continues to build up his program at the University of North Carolina, the ex-Patriots head coach is looking to bring in a familiar name to Chapel Hill in the years ahead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8068fb-b20b-4697-a310-ef4eb3242cda",
   "metadata": {},
   "source": [
    "Upload the labelled training data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d60a1c27-017c-443b-9a71-4b8505dcbb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Trying to upload file [traningdata-updated.json] with key [ner/target/traningdata-updated.json] to the bucket [jianrzha-test]... SUCCESS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "res = project.export()\n",
    "if res['status'] == 200:\n",
    "    exported_file = res['filename']\n",
    "    target_file = 'traningdata-updated.json'\n",
    "    os.rename(exported_file, target_file)\n",
    "    dir_model = BucketMeta(\n",
    "                       bucket_name=s3_env.bucket_name,\n",
    "                       client=s3_env.client,\n",
    "                       file_name=target_file,\n",
    "                       prefix='ner/target',\n",
    "                       exclude_dirs_set=['logs'])\n",
    "    upload_file(dir_model)\n",
    "    os.remove(target_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e24a389-f27b-47a3-91ea-dba3ef668cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
