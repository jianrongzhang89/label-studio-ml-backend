{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdc8cab4",
   "metadata": {},
   "source": [
    "# Workbench and Label Studio Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f8209d",
   "metadata": {},
   "source": [
    "First, install the dependencies, including label-studio-sdk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05241b64-faf9-439d-9ad0-536bc36138c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -U transformers\n",
    "!pip install -U accelerate\n",
    "!pip install -U datasets\n",
    "!pip install -q diffusers  peft torch torchvision \n",
    "!pip install -q ipywidgets jupyterlab dataclass_wizard\n",
    "!pip install seqeval\n",
    "!pip install evaluate\n",
    "!pip install label-studio-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacbfa99",
   "metadata": {},
   "source": [
    "# Download training data from AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486c53c-3303-4694-be34-e73b3ad6b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the following 3 variables before proceeding.\n",
    "import_test_data_from_aws = True # Set to True to import data stored in S3 bucket to the Label Studio project\n",
    "existing_project_id = 0 # If 0, a new project will be created. Otherwise set to the existing Label Studio project ID\n",
    "project_title = 'Huggingface Project' # Title of the Label Studio project. Ignored if existing_project_id > 0.\n",
    "\n",
    "if import_test_data_from_aws:\n",
    "    %run ./transfer-aws.ipynb\n",
    "    project_title = 'Huggingface Project'\n",
    "    prefix = \"ner-source\"  # Directory where the input data file is stored in AWS S3 bucket\n",
    "    input_file='trainingdata-1000-before.json'\n",
    "    #test with the sample training data updated by Label Studio \n",
    "    #prefix = \"ner-labelled\"\n",
    "    #input_file='trainingdata-1000-after.json'\n",
    "\n",
    "    s3_env: S3Env = init()\n",
    "    dir_model = BucketMeta(\n",
    "                       bucket_name=s3_env.bucket_name,\n",
    "                       client=s3_env.client,\n",
    "                       file_name=input_file,\n",
    "                       prefix=prefix,\n",
    "                       exclude_dirs_set=['logs'])\n",
    "    download_file(dir_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55b2d1e-45f5-4e32-9a06-66ae289a0beb",
   "metadata": {},
   "source": [
    "# Connect to Label Studio and Create a Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60002d1e-323b-4765-aa5c-ebca95a19185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define the URL where Label Studio is accessible and the API key for your user account\n",
    "LABEL_STUDIO_URL = os.environ.get('LABEL_STUDIO_URL')\n",
    "# API key is available at the Account & Settings > Access Tokens page in Label Studio UI\n",
    "API_KEY = os.environ.get('API_KEY')\n",
    "\n",
    "# Import the SDK client module\n",
    "from label_studio_sdk import Client\n",
    "from label_studio_sdk.label_interface.create import choices\n",
    "\n",
    "# Connect to the Label Studio Client and check the connection\n",
    "ls = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
    "ls.check_connection()\n",
    "\n",
    "# Label Studio project configuration\n",
    "label_config = \"\"\"\n",
    "<View>\n",
    "  <Labels name=\"label\" toName=\"text\">\n",
    "    <Label value=\"PER\" background=\"red\"/>\n",
    "    <Label value=\"ORG\" background=\"darkorange\"/>\n",
    "    <Label value=\"LOC\" background=\"orange\"/>\n",
    "    <Label value=\"MISC\" background=\"green\"/>\n",
    "  </Labels>\n",
    "  <Text name=\"text\" value=\"$text\"/>\n",
    "</View>\n",
    "    \"\"\"\n",
    "\n",
    "if existing_project_id == 0:\n",
    "    # Create a Label Studio project\n",
    "    project = ls.start_project(\n",
    "      title=project_title,\n",
    "      label_config=label_config,\n",
    "    )\n",
    "    print(f\"Created Lable Studio project {project_title} with ID {project.get_params()['id']}.\")\n",
    "else:\n",
    "    project = ls.get_project(existing_project_id)\n",
    "    project_title = project.get_params()['title']\n",
    "    print(f\"Use existing Lable Studio project with ID {existing_project_id} and title {project_title}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b7816-4a1a-4c68-a29c-212973283f00",
   "metadata": {},
   "source": [
    "# Import Labelled Data from Label Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e737bb63-a2dc-4a6f-ac61-cb9150bcc8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag names\n",
    "names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "index2tag = {idx:tag for idx, tag in enumerate(names)}\n",
    "tag2index = {tag:idx for idx, tag in enumerate(names)}\n",
    "tag2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f20308-9de3-4622-96e3-f9854b2b764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if import_test_data_from_aws:\n",
    "    result=project.import_tasks(tasks=input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc6bf5a-82a4-491d-a771-eb49aec04c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After user has done labelling in Label Studio, retrieve that data from Label Studio\n",
    "tasks = project.get_tasks()\n",
    "tasks_count = len(tasks)\n",
    "if tasks_count == 0:\n",
    "    print('No tasks exported from Label Studio project')\n",
    "else:\n",
    "    print(f'{tasks_count} task(s) exported from Label Studio project')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7ad0d0-fbd0-43e6-b701-c980d7855382",
   "metadata": {},
   "source": [
    "# Create a tokenizer and data collator for the base NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041ce8b-ff04-4be8-aca0-4aabcb1d0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "#model_checkpoint = \"distilbert-base-cased\"\n",
    "model_checkpoint = 'dslim/bert-base-NER'\n",
    "#model_checkpoint = \"/opt/app-root/src/label-studio-ml-backend/label_studio_ml/examples/huggingface_ner/distilbert-finetuned-ner/checkpoint-5268\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f04a7-3a81-4d78-a6dc-b9efdc5d4eef",
   "metadata": {},
   "source": [
    "# Transform labelled data to a tokenized dataset for NER model fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae60a22-4628-4390-aa3f-3e02794190ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_studio_sdk.label_interface.objects import PredictionValue\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Dict\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "import pathlib\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from datasets import Dataset, ClassLabel, Value, Sequence, Features\n",
    "from functools import partial\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "def is_valid_url(path):\n",
    "    # Check if the text is a valid URL\n",
    "    try:\n",
    "        result = urlparse(path)\n",
    "        return all([result.scheme, result.netloc])\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_preload_needed(url):\n",
    "    if url.startswith('upload') or url.startswith('/upload'):\n",
    "        url = '/data' + ('' if url.startswith('/') else '/') + url\n",
    "\n",
    "    is_uploaded_file = url.startswith('/data/upload')\n",
    "    is_local_storage_file = url.startswith('/data/') and '?d=' in url\n",
    "    is_cloud_storage_file = url.startswith('s3:') or url.startswith('gs:') or url.startswith('azure-blob:')\n",
    "    path_exists = os.path.exists(url)\n",
    "\n",
    "    return (\n",
    "        is_uploaded_file\n",
    "        or is_local_storage_file\n",
    "        or is_cloud_storage_file\n",
    "        or is_valid_url(url)\n",
    "        or path_exists\n",
    "    )\n",
    "\n",
    "def preload_task_data(task: Dict, value=None, read_file=True):\n",
    "    \"\"\" Preload task_data values using get_local_path() if values are URI/URL/local path.\n",
    "\n",
    "    Args:\n",
    "        task: Task root.\n",
    "        value: task['data'] if it's None.\n",
    "        read_file: If True, read file content. Otherwise, return file path only.\n",
    "\n",
    "    Returns:\n",
    "        Any: Preloaded task data value.\n",
    "    \"\"\"\n",
    "    # recursively preload dict\n",
    "    if isinstance(value, dict):\n",
    "        for key, item in value.items():\n",
    "            value[key] = preload_task_data(task=task, value=item, read_file=read_file)\n",
    "        return value\n",
    "\n",
    "    # recursively preload list\n",
    "    elif isinstance(value, list):\n",
    "        return [\n",
    "            preload_task_data(task=task, value=item, read_file=read_file)\n",
    "            for item in value\n",
    "        ]\n",
    "\n",
    "    # preload task data if value is URI/URL/local path\n",
    "    elif isinstance(value, str) and is_preload_needed(value):\n",
    "        filepath = self.get_local_path(url=value, task_id=task.get('id'))\n",
    "        if not read_file:\n",
    "            return filepath\n",
    "        with open(filepath, 'r') as f:\n",
    "            return f.read()\n",
    "\n",
    "    # keep value as is\n",
    "    return value\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            current_word = word_id\n",
    "            label =  -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            label = labels[word_id]\n",
    "            if label%2==1:\n",
    "                label = label + 1\n",
    "            new_labels.append(label)\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples['tokens'], truncation=True,is_split_into_words=True)\n",
    "    all_labels = examples['ner_tags']\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    tokenized_inputs['labels'] = new_labels\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f6dbe0-87fa-4502-9bde-2b10d927d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_studio_sdk.label_interface import LabelInterface\n",
    "label_interface = LabelInterface(config=label_config)\n",
    "\n",
    "ds_raw = []\n",
    "no_label = 'O'\n",
    "from_name, to_name, value = label_interface.get_first_tag_occurence('Labels', 'Text')\n",
    "for task in tasks:\n",
    "    if task['annotations'] != None:\n",
    "        for annotation in task['annotations']:\n",
    "            if not annotation.get('result'):\n",
    "                continue\n",
    "            spans = [{'label': r['value']['labels'][0], 'start': r['value']['start'], 'end': r['value']['end']} for r in annotation['result']]\n",
    "            spans = sorted(spans, key=lambda x: x['start'])\n",
    "            text = preload_task_data(task, task['data'][value])\n",
    "            # insert tokenizer.pad_token to the unlabeled chunks of the text in-between the labeled spans, as well as to the beginning and end of the text\n",
    "            last_end = 0\n",
    "            all_spans = []\n",
    "            for span in spans:\n",
    "                if last_end < span['start']:\n",
    "                    all_spans.append({'label': no_label, 'start': last_end, 'end': span['start']})\n",
    "                all_spans.append(span)\n",
    "                last_end = span['end']\n",
    "            if last_end < len(text):\n",
    "                all_spans.append({'label': no_label, 'start': last_end, 'end': len(text)})\n",
    "            # now tokenize chunks separately and add them to the dataset\n",
    "            item = {'id': task['id'], 'tokens': [], 'ner_tags': []}\n",
    "            for span in all_spans:\n",
    "                #tokens = tokenizer.tokenize(text[span['start']:span['end']])\n",
    "                tokens = str(text[span['start']:span['end']]).split()\n",
    "                item['tokens'].extend(tokens)\n",
    "                if span['label'] == no_label:\n",
    "                    item['ner_tags'].extend([tag2index[no_label]] * len(tokens))\n",
    "                else:\n",
    "                    label = 'B-' + span['label']\n",
    "                    item['ner_tags'].append(tag2index[label])\n",
    "                    if len(tokens) > 1:\n",
    "                        label = 'I-' + span['label']\n",
    "                        item['ner_tags'].extend([tag2index[label] for _ in range(1, len(tokens))])\n",
    "            ds_raw.append(item)\n",
    "print(\"Dataset[0]:\", ds_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a97ea25-43f9-4db1-9dd0-3d4eb283d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to huggingface dataset\n",
    "# Define the features of your dataset\n",
    "features = Features({\n",
    "    'id': Value('string'),\n",
    "    'tokens': Sequence(Value('string')),\n",
    "    'ner_tags': Sequence(ClassLabel(names=list(tag2index.keys())))})\n",
    "\n",
    "hf_dataset = Dataset.from_list(ds_raw, features=features)\n",
    "tokenized_dataset_from_labelstudio = hf_dataset.map(tokenize_and_align_labels, \n",
    "                                   batched=True,\n",
    "                                   remove_columns=['id', 'tokens', 'ner_tags'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09797bd2-0fd5-430a-ac69-627696916e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset_from_labelstudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de9288e-823c-4a76-a2e7-13e3eeb25ec7",
   "metadata": {},
   "source": [
    "# Prepare tokenized dataset for for model training validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38120518-78a3-4abb-9d6d-c0e0e830fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "data = load_dataset(\"conllpp\")  # use published dataset for validation\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad3836-b751-4550-a387-8a95cafae555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_names(batch):\n",
    "    tag_name = {'ner_tags_str': [tags.int2str(idx) for idx in batch['ner_tags']]}\n",
    "    return tag_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef27af-2d9c-4ea3-8b0c-ba5a1c2cc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = data['validation'].features['ner_tags'].feature\n",
    "new_feature = data['validation'].features['ner_tags']\n",
    "label_names = new_feature.feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9841d879-8587-4ed5-9a4a-d84b692410ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a8566-e2a3-463c-a89b-5850664fb543",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ac328-72f3-4d9b-ace1-6520f0aab5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            current_word = word_id\n",
    "            label =  -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            label = labels[word_id]\n",
    "            if label%2==1:\n",
    "                label = label + 1\n",
    "            new_labels.append(label)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea040121-7bc8-4c3d-a852-087ca54d84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples['tokens'], truncation=True,is_split_into_words=True)\n",
    "    all_labels = examples['ner_tags']\n",
    "    \n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    tokenized_inputs['labels'] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c2124-1b00-4de0-a9ea-8a33345b9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = data.map(tokenize_and_align_labels, batched=True, remove_columns=data['validation'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b373a8-6c41-469f-bcd3-7ac9fcd77a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540b508-8242-4592-b12f-03df16a5b175",
   "metadata": {},
   "source": [
    "# Metrics for model training measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1da581-2165-4ff1-b92e-6d9c81a635fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the whole dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "metric = evaluate.load('seqeval')\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [[label_names[p] for p, l in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\"precision\": all_metrics['overall_precision'],\n",
    "            \"recall\": all_metrics['overall_recall'],\n",
    "            \"f1\": all_metrics['overall_f1'],\n",
    "            \"accuracy\": all_metrics['overall_accuracy']}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7863e2-e670-4e5e-83f9-703c1e998495",
   "metadata": {},
   "source": [
    "# Train/fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2421b30-f2c0-484f-b391-3f8b42ddcece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, \n",
    "                                                        id2label=index2tag,\n",
    "                                                        label2id=tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d7815-f682-4b61-8685-a74d612465ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "args = TrainingArguments(\"distilbert-finetuned-ner-1\",\n",
    "                         eval_strategy=\"epoch\",\n",
    "                         save_strategy=\"epoch\",\n",
    "                         learning_rate=2e-5,\n",
    "                         num_train_epochs=2,\n",
    "                         weight_decay=0.01)\n",
    "\n",
    "from transformers import Trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  train_dataset = tokenized_dataset_from_labelstudio,  \n",
    "                  #train_dataset = tokenized_datasets['train'].select(range(1000)),\n",
    "                  eval_dataset = tokenized_datasets['validation'].select(range(500)),\n",
    "                  data_collator = data_collator,\n",
    "                  compute_metrics = compute_metrics,\n",
    "                  tokenizer = tokenizer)\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29cf77f-8075-4c3d-8a12-0780531520ad",
   "metadata": {},
   "source": [
    "# Checking model predictions after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b283f-804f-4ab9-9c04-ebef3075c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "checkpoint = \"/opt/app-root/src/label-studio-ml-backend/label_studio_ml/examples/huggingface_ner/rhoai-poc/distilbert-finetuned-ner-1/checkpoint-204\"\n",
    "token_classifier = pipeline(\"token-classification\", model=checkpoint, aggregation_strategy=\"simple\")\n",
    "token_classifier(\"As Bill Belichick continues to build up his program at the University of North Carolina, the ex-Patriots head coach is looking to bring in a familiar name to Chapel Hill in the years ahead. Through Belichick’s recruiting efforts, the Tar Heels have now extended an offer to LeGarrette Blount Jr. — with the 2028 prospect posting the news on social media Wednesday. Blount — whose father played for the Patriots for four seasons — plays defensive back and wide receiver at Hamilton High School in Chandler, Arizona.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427f5a0-0ecd-4de1-bd3c-a9f540d8a4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
